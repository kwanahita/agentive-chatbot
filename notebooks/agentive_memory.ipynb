{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentive Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'agents/dog_memory.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     43\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(agent_dir, filename)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     45\u001b[0m         memory_data \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(file)\n\u001b[1;32m     47\u001b[0m     route \u001b[38;5;241m=\u001b[39m Route(\n\u001b[1;32m     48\u001b[0m         name\u001b[38;5;241m=\u001b[39mmemory_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroute_name\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     49\u001b[0m         utterances\u001b[38;5;241m=\u001b[39mmemory_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutterances\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     50\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/chatbot/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'agents/dog_memory.yaml'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, Layout\n",
    "from IPython.display import display\n",
    "from dotenv import load_dotenv\n",
    "from semantic_router import Route\n",
    "from semantic_router.encoders import OpenAIEncoder\n",
    "from semantic_router.layer import RouteLayer\n",
    "from openai import OpenAI\n",
    "import yaml\n",
    "from enum import Enum\n",
    "\n",
    "load_dotenv('.env')\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# separate this so we have separate semantic routes for categories and all subcategories\n",
    "agent_dir = \"agents\"\n",
    "all_routes = []\n",
    "prompts = {}\n",
    "\n",
    "for filename in os.listdir(agent_dir):\n",
    "    if filename.endswith(\".yaml\"):\n",
    "        filepath = os.path.join(agent_dir, filename)\n",
    "        with open(filepath, 'r') as file:\n",
    "            agent_data = yaml.safe_load(file)\n",
    "\n",
    "        if 'utterances' in agent_data:\n",
    "        # 1 Route object per agent\n",
    "            route = Route(\n",
    "                name=agent_data['route_name'],\n",
    "                utterances=agent_data['utterances']\n",
    "            )\n",
    "            all_routes.append(route)\n",
    "        if 'prompt' in agent_data:\n",
    "        # Stores the agentive prompt in dictionary\n",
    "            prompts[agent_data['agent_name']] = agent_data['prompt']\n",
    "\n",
    "memory_routes = []\n",
    "memory_dir = \"memory\"\n",
    "\n",
    "for filename in os.listdir(memory_dir):\n",
    "    if filename.endswith(\".yaml\"):\n",
    "        filepath = os.path.join(agent_dir, filename)\n",
    "        with open(filepath, 'r') as file:\n",
    "            memory_data = yaml.safe_load(file)\n",
    "        \n",
    "        route = Route(\n",
    "            name=memory_data['route_name'],\n",
    "            utterances=memory_data['utterances']\n",
    "            )\n",
    "        memory_routes.append(route)\n",
    "\n",
    "encoder = OpenAIEncoder()\n",
    "question_rl = RouteLayer(encoder=encoder, routes=all_routes)\n",
    "memory_rl = RouteLayer(encoder = encoder, routes = memory_routes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables to store the default system prompt and the catch-all prompt (to be used when no route is identified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('syst_prompt.txt', 'r') as f:\n",
    "    system_prompt = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defines logic for updating, activating, and deactivating prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns one route per input\n",
    "def classify_question(prompt: str) -> str | list[str]:\n",
    "    r = question_rl(prompt)\n",
    "    return r.name\n",
    "\n",
    "class STATES(Enum):\n",
    "    OK = 0\n",
    "    ANNOYED = 1\n",
    "    FRUSTRATED = 2\n",
    "    ANGRY = 3\n",
    "    ENRAGED = 4\n",
    "\n",
    "CURRENT_STATE = STATES.OK\n",
    "\n",
    "def state_to_prompt(state: STATES) -> str:\n",
    "    state_mapping = {\n",
    "        STATES.OK: \"ok\",\n",
    "        STATES.ANNOYED: \"annoyed\",\n",
    "        STATES.FRUSTRATED: \"frustrated\",\n",
    "        STATES.ANGRY: \"angry\",\n",
    "        STATES.ENRAGED: \"enraged\",\n",
    "    }\n",
    "    return state_mapping[state]\n",
    "\n",
    "def update_prompt(user_input: str) -> str:\n",
    "    global CURRENT_STATE\n",
    "    question_category = classify_question(user_input)\n",
    "    print(f\"route: {question_category}\")\n",
    "    if question_category == 'escalate':\n",
    "        if CURRENT_STATE != STATES.ENRAGED:\n",
    "            CURRENT_STATE = STATES(CURRENT_STATE.value + 1)\n",
    "    elif question_category == 'de_escalate':\n",
    "        if CURRENT_STATE != STATES.OK:\n",
    "            CURRENT_STATE = STATES(CURRENT_STATE.value - 1)\n",
    "    elif question_category is None:\n",
    "        if CURRENT_STATE != STATES.OK:\n",
    "            CURRENT_STATE = STATES(CURRENT_STATE.value + 1)\n",
    "    prompt_key = state_to_prompt(CURRENT_STATE)\n",
    "    prompt = prompts[prompt_key]\n",
    "    return prompt, question_category\n",
    "\n",
    "def update_memory(user_input: str) -> None:\n",
    "    \"\"\"write code for updating memory, flag can be checked in main body, separate the semantic routes\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot():  \n",
    "    def __init__(self, api_key, role): \n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.role = role\n",
    "        self.messages = [{\"role\": \"user\", \"content\": \"\"}]\n",
    "        self.all_conversations = []  # Store all conversations\n",
    "    \n",
    "    def query(self, query: str, prompt: str, route: str) -> None:\n",
    "        self.messages.append({\"role\": \"user\", \"content\": query})\n",
    "        self.messages.insert(0, {\"role\": \"system\", \"content\": self.role + prompt})\n",
    "        try:\n",
    "            stream = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-2024-08-06\", messages=self.messages,\n",
    "                stream=True,\n",
    "            )\n",
    "            text = []\n",
    "            for part in stream:\n",
    "                if part.choices[0].delta.content is not None:\n",
    "                    response_part = part.choices[0].delta.content\n",
    "                    print(response_part, end=\"\", flush=True)\n",
    "                    text.append(response_part)\n",
    "            full_reply_content = ''.join([m for m in text if m is not None])\n",
    "            self.messages.append({\"role\": \"assistant\", \"content\": full_reply_content})\n",
    "            self.messages.pop(0)  # Remove the role message for the next query\n",
    "            self.all_conversations.append(f\"\\nRoute: {route} \\nCurrent prompt: {prompt}\")\n",
    "            self.all_conversations.append(self.messages[-2:])\n",
    "            print('\\n')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "    def save_whole_conversation(self, filename):\n",
    "        with open(f\"transcripts/{filename}\", \"w\") as file:\n",
    "            for conversation in self.all_conversations:\n",
    "                if isinstance(conversation, str):\n",
    "                    # If it's a string, write it directly\n",
    "                    file.write(conversation + \"\\n\")\n",
    "                elif isinstance(conversation, list):\n",
    "                    # If it's a list (e.g., self.messages[-2:]), handle it accordingly\n",
    "                    for message in conversation:\n",
    "                        if message[\"role\"] == \"user\":\n",
    "                            file.write(\"User: \" + message[\"content\"] + \"\\n\")\n",
    "                        elif message[\"role\"] == \"assistant\":\n",
    "                            file.write(\"Agent: \" + message[\"content\"] + \"\\n\")\n",
    "\n",
    "rpa = ChatBot(api_key=api_key, role = system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_pasted_submit(b):\n",
    "    pasted_content = pasted_input_field.value\n",
    "    PROMPT, ROUTE = update_prompt(pasted_content)\n",
    "    print(f\"current prompt: {PROMPT}\")\n",
    "    rpa.query(pasted_content, prompt=PROMPT, route=ROUTE)\n",
    "    time.sleep(1)\n",
    "    pasted_input_field.value = \"\"\n",
    "\n",
    "def on_save_click(b):\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{timestamp}.txt\"\n",
    "    rpa.save_whole_conversation(filename)\n",
    "\n",
    "# Additional input field for pasted content\n",
    "pasted_input_field = widgets.Textarea(\n",
    "    placeholder='Type here :)',\n",
    "    layout=widgets.Layout(width='100%', height='50px')  # Adjust height as needed\n",
    ")\n",
    "# Button for pasted content submission\n",
    "pasted_submit_button = widgets.Button(description='Submit')\n",
    "pasted_submit_button.style.button_color = 'lightpink'  # Change to your desired color\n",
    "\n",
    "# Button for saving chat history\n",
    "save_button = widgets.Button(description='Save')\n",
    "save_button.style.button_color = 'lightgrey'  # Change to your desired color\n",
    "\n",
    "pasted_submit_button.on_click(on_pasted_submit)\n",
    "save_button.on_click(on_save_click)\n",
    "\n",
    "# Arrange buttons side by side and center them using HBox\n",
    "button_layout = HBox([pasted_submit_button, save_button], layout=Layout(justify_content='center'))\n",
    "\n",
    "# Display the input fields and the button layout\n",
    "display(pasted_input_field, button_layout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
