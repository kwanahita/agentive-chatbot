{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentive Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, Layout\n",
    "from IPython.display import display\n",
    "from dotenv import load_dotenv\n",
    "from semantic_router import Route\n",
    "from semantic_router.encoders import OpenAIEncoder\n",
    "from semantic_router.layer import RouteLayer\n",
    "from openai import OpenAI\n",
    "import yaml\n",
    "import json\n",
    "from enum import Enum\n",
    "\n",
    "load_dotenv('.env')\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "memory_routes = []\n",
    "memory_dir = \"memory\"\n",
    "\n",
    "for filename in os.listdir(memory_dir):\n",
    "    if filename.endswith(\".yaml\"):\n",
    "        filepath = os.path.join(memory_dir, filename)\n",
    "        with open(filepath, 'r') as file:\n",
    "            memory_data = yaml.safe_load(file)\n",
    "        \n",
    "        route = Route(\n",
    "            name=memory_data['route_name'],\n",
    "            utterances=memory_data['utterances']\n",
    "            )\n",
    "        memory_routes.append(route)\n",
    "\n",
    "encoder = OpenAIEncoder()\n",
    "memory_rl = RouteLayer(encoder = encoder, routes = memory_routes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables to store the default system prompt and the scenario prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('syst_prompt.txt', 'r') as f:\n",
    "    system_prompt = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defines logic for updating, activating, and deactivating prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot():  \n",
    "    def __init__(self, api_key, role): \n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.role = role\n",
    "        self.messages = [{\"role\": \"user\", \"content\": \"\"}]\n",
    "        self.all_conversations = []  # Store all conversations\n",
    "    \n",
    "    def query(self, query: str, print_response: bool = True) -> None:\n",
    "        self.messages.append({\"role\": \"user\", \"content\": query})\n",
    "        self.messages.insert(0, {\"role\": \"system\", \"content\": self.role})\n",
    "        try:\n",
    "            stream = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-2024-08-06\", messages=self.messages,\n",
    "                stream=True,\n",
    "            )\n",
    "            text = []\n",
    "            for part in stream:\n",
    "                if part.choices[0].delta.content is not None:\n",
    "                    response_part = part.choices[0].delta.content\n",
    "                    if print_response:\n",
    "                        print(response_part, end=\"\", flush=True)\n",
    "                    text.append(response_part)\n",
    "            full_reply_content = ''.join([m for m in text if m is not None])\n",
    "            self.messages.append({\"role\": \"assistant\", \"content\": full_reply_content})\n",
    "            self.messages.pop(0)  # Remove the role message for the next query\n",
    "            self.all_conversations.append(self.messages[-2:])\n",
    "            print('\\n')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "    def save_whole_conversation(self, filename):\n",
    "        with open(f\"transcripts/{filename}\", \"w\") as file:\n",
    "            for conversation in self.all_conversations:\n",
    "                if isinstance(conversation, str):\n",
    "                    # If it's a string, write it directly\n",
    "                    file.write(conversation + \"\\n\")\n",
    "                elif isinstance(conversation, list):\n",
    "                    # If it's a list (e.g., self.messages[-2:]), handle it accordingly\n",
    "                    for message in conversation:\n",
    "                        if message[\"role\"] == \"user\":\n",
    "                            file.write(\"User: \" + message[\"content\"] + \"\\n\")\n",
    "                        elif message[\"role\"] == \"assistant\":\n",
    "                            file.write(\"Agent: \" + message[\"content\"] + \"\\n\")\n",
    "\n",
    "rpa = ChatBot(api_key=api_key, role = system_prompt)\n",
    "\n",
    "mem = ChatBot(api_key = api_key, role = \"Summarise the user input in a short bullet point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns one route per input\n",
    "def classify_content(prompt: str) -> str | list[str]:\n",
    "    r = memory_rl(prompt)\n",
    "    return r.name\n",
    "\n",
    "def update_memory(user_input: str) -> None:\n",
    "    mem.query(user_input, print_response = False)\n",
    "    summary = mem.messages[-1][\"content\"]\n",
    "\n",
    "    # Prepare the text to be appended\n",
    "    entry = f\"{summary}\\n\"\n",
    "\n",
    "    # Append the entry to the memory.txt file\n",
    "    with open(\"memory.txt\", \"a\") as file:\n",
    "        file.write(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef605d35bb03441b80d03e68a515c976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', layout=Layout(height='50px', width='100%'), placeholder='Type here :)')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caafd56ca5240fc8a5d958a32947378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Submit', style=ButtonStyle(button_color='lightpink')), Button(description='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How's your day going?\n",
      "\n",
      "I'm really sorry to hear that. Losing a pet is incredibly tough. How are you holding up, and is there anything specific you'd like to talk about or share about your dogs?\n",
      "\n",
      "route: dog\n",
      "- User is feeling sad due to the loss of their two dogs.\n",
      "\n",
      "Bruno and Lola sound like they were really special. Cockapoos and Cavapoos are such loving dogs. Do you have any favorite memories with them that you'd like to share? Sometimes talking about the good times can be comforting.\n",
      "\n",
      "route: dog\n",
      "- User's dogs, Bruno (a Cockapoo) and Lola (a Cavapoo), have passed away.\n",
      "\n",
      "Oh, I see. Are they missing? That must be really stressful. Have you been able to search the area or put up any notices to help find them?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def on_pasted_submit(b):\n",
    "    pasted_content = pasted_input_field.value\n",
    "    rpa.query(pasted_content)\n",
    "    route = classify_content(pasted_content)\n",
    "    if route == \"dog_memories\":\n",
    "        print(\"route: dog\")\n",
    "        update_memory(pasted_content)\n",
    "    time.sleep(1)\n",
    "    pasted_input_field.value = \"\"\n",
    "\n",
    "def on_save_click(b):\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{timestamp}.txt\"\n",
    "    rpa.save_whole_conversation(filename)\n",
    "\n",
    "# Additional input field for pasted content\n",
    "pasted_input_field = widgets.Textarea(\n",
    "    placeholder='Type here :)',\n",
    "    layout=widgets.Layout(width='100%', height='50px')  # Adjust height as needed\n",
    ")\n",
    "# Button for pasted content submission\n",
    "pasted_submit_button = widgets.Button(description='Submit')\n",
    "pasted_submit_button.style.button_color = 'lightpink'  # Change to your desired color\n",
    "\n",
    "# Button for saving chat history\n",
    "save_button = widgets.Button(description='Save')\n",
    "save_button.style.button_color = 'lightgrey'  # Change to your desired color\n",
    "\n",
    "pasted_submit_button.on_click(on_pasted_submit)\n",
    "save_button.on_click(on_save_click)\n",
    "\n",
    "# Arrange buttons side by side and center them using HBox\n",
    "button_layout = HBox([pasted_submit_button, save_button], layout=Layout(justify_content='center'))\n",
    "\n",
    "# Display the input fields and the button layout\n",
    "display(pasted_input_field, button_layout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
