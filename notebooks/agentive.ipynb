{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentive Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'avatar_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m         all_routes\u001b[38;5;241m.\u001b[39mappend(route)\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;66;03m# Stores the agentive prompt in dictionary\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m         prompts[\u001b[43magent_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavatar_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m] \u001b[38;5;241m=\u001b[39m agent_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m prompts\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, prompt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'avatar_name'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, Layout\n",
    "from IPython.display import display\n",
    "from dotenv import load_dotenv\n",
    "from semantic_router import Route\n",
    "from semantic_router.encoders import OpenAIEncoder\n",
    "from semantic_router.layer import RouteLayer\n",
    "from openai import OpenAI\n",
    "import yaml\n",
    "\n",
    "load_dotenv('.env')\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(f\"Loaded API key: {api_key}\")\n",
    "\n",
    "agent_dir = \"agents\"\n",
    "all_routes = []\n",
    "prompts = {}\n",
    "\n",
    "for filename in os.listdir(agent_dir):\n",
    "    if filename.endswith(\".yaml\"):\n",
    "        filepath = os.path.join(agent_dir, filename)\n",
    "        with open(filepath, 'r') as file:\n",
    "            agent_data = yaml.safe_load(file)\n",
    "\n",
    "        # 1 Route object per agent\n",
    "        route = Route(\n",
    "            name=agent_data['agent_name'],\n",
    "            utterances=agent_data['utterances']\n",
    "        )\n",
    "        all_routes.append(route)\n",
    "\n",
    "        # Stores the agentive prompt in dictionary\n",
    "        prompts[agent_data['agent_name']] = agent_data['prompt']\n",
    "\n",
    "for key, value in prompts.items():\n",
    "    print(f\"name: {key}, prompt: {value}\")\n",
    "\n",
    "encoder = OpenAIEncoder()\n",
    "question_rl = RouteLayer(encoder=encoder, routes=all_routes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables to store the default system prompt and the catch-all prompt (used when no route is identified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a woman in your early 30s thinking about purchasing health insurance. \n",
    "This is your first meeting with the insurance agent. You are having a conversation with the insurance agent.\n",
    "\"\"\"\n",
    "\n",
    "catchall_prompt = \"\"\"\n",
    "Your main goals for this conversation is to find out more about the insurance policies that the insurance agent sells, and also ascertain if the agent is trustworthy to work with.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defines logic for updating, activating, and deactivating prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns one route per input\n",
    "def classify_question(prompt: str) -> str | list[str]:\n",
    "    r = question_rl(prompt)\n",
    "    return r.name\n",
    "\n",
    "OFFENDED_BOOL = False\n",
    "DISTANT_BOOL = False\n",
    "DISTANT_TIMER = 0\n",
    "\n",
    "def update_prompt(user_input: str) -> str:\n",
    "    global OFFENDED_BOOL\n",
    "    global DISTANT_BOOL\n",
    "    global DISTANT_TIMER\n",
    "    question_category = classify_question(user_input)\n",
    "    print(f\"route: {question_category}\")\n",
    "    prompt = \"\"\n",
    "    if question_category == \"offended\":\n",
    "        if not OFFENDED_BOOL:\n",
    "            prompt = prompts[\"offended\"]\n",
    "            OFFENDED_BOOL = True\n",
    "        else:\n",
    "            prompt = prompts[\"enraged\"]\n",
    "    elif question_category == \"distant\" and OFFENDED_BOOL:\n",
    "        prompt = prompts[\"distant\"]\n",
    "        OFFENDED_BOOL = False\n",
    "        DISTANT_BOOL = True\n",
    "        DISTANT_TIMER += 1\n",
    "    elif DISTANT_TIMER > 5:\n",
    "        prompt = catchall_prompt\n",
    "        DISTANT_BOOL = False\n",
    "    elif DISTANT_BOOL:\n",
    "        prompt = prompts[\"distant\"]\n",
    "        DISTANT_TIMER += 1\n",
    "    elif OFFENDED_BOOL:\n",
    "        prompt = prompts[\"offended\"]\n",
    "    else:\n",
    "        prompt = catchall_prompt\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot():  \n",
    "    def __init__(self, api_key, role): \n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.role = role\n",
    "        self.messages = [{\"role\": \"user\", \"content\": \"\"}]\n",
    "        self.all_conversations = []  # Store all conversations\n",
    "    \n",
    "    def query(self, query: str, prompt: str) -> None:\n",
    "        self.messages.append({\"role\": \"user\", \"content\": query})\n",
    "        self.messages.insert(0, {\"role\": \"system\", \"content\": self.role + prompt})\n",
    "        try:\n",
    "            stream = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-2024-08-06\", messages=self.messages,\n",
    "                stream=True,\n",
    "            )\n",
    "            text = []\n",
    "            for part in stream:\n",
    "                if part.choices[0].delta.content is not None:\n",
    "                    response_part = part.choices[0].delta.content\n",
    "                    print(response_part, end=\"\", flush=True)\n",
    "                    text.append(response_part)\n",
    "            full_reply_content = ''.join([m for m in text if m is not None])\n",
    "            self.messages.append({\"role\": \"assistant\", \"content\": full_reply_content})\n",
    "            self.messages.pop(0)  # Remove the role message for the next query\n",
    "\n",
    "            # Save the current conversation to all_conversations without the initial user prompt\n",
    "            conversation_log = [{\"role\": \"system\", \"content\": self.role + prompt }] + self.messages[1:]\n",
    "            self.all_conversations.append(conversation_log)\n",
    "            print('\\n')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "    def save_all_conversations(self, filename):\n",
    "        with open(f\"rag/intro/{filename}\", \"w\") as file:\n",
    "            for conversation in self.all_conversations:\n",
    "                for message in conversation:\n",
    "                    if message[\"role\"] == \"user\":\n",
    "                        file.write(\"User: \" + message[\"content\"] + \"\\n\")\n",
    "                    elif message[\"role\"] == \"assistant\":\n",
    "                        file.write(\"Assistant: \" + message[\"content\"] + \"\\n\")\n",
    "                file.write(\"\\n---\\n\")  # Add a separator between conversations\n",
    "\n",
    "rpa = ChatBot(api_key=api_key, role = system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ff836f2d9d43de980874318ec10f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', layout=Layout(height='50px', width='100%'), placeholder='Type here :)')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cad9f2c67c94fafa08c806b94ea5986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Submit', style=ButtonStyle(button_color='lightpink')), Button(description='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def on_pasted_submit(b):\n",
    "    pasted_content = pasted_input_field.value\n",
    "    PROMPT = update_prompt(pasted_content)\n",
    "    print(f\"current prompt: {PROMPT}\")\n",
    "    rpa.query(pasted_content, prompt=PROMPT)  # Process the pasted content\n",
    "    time.sleep(1)  # Add a delay between iterations if needed\n",
    "    pasted_input_field.value = ''  # Clear the field after submission\n",
    "    # Save all conversations after iterations are completed\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"transcript_{timestamp}.txt\"\n",
    "    rpa.save_all_conversations(filename)\n",
    "\n",
    "def on_save_click(b):\n",
    "    # Generate a unique filename based on the current timestamp\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"transcript_{timestamp}.txt\"\n",
    "    rpa.save_all_conversations(filename)\n",
    "\n",
    "# Additional input field for pasted content\n",
    "pasted_input_field = widgets.Textarea(\n",
    "    placeholder='Type here :)',\n",
    "    layout=widgets.Layout(width='100%', height='50px')  # Adjust height as needed\n",
    ")\n",
    "# Button for pasted content submission\n",
    "pasted_submit_button = widgets.Button(description='Submit')\n",
    "pasted_submit_button.style.button_color = 'lightpink'  # Change to your desired color\n",
    "\n",
    "# Button for saving chat history\n",
    "save_button = widgets.Button(description='Save')\n",
    "save_button.style.button_color = 'lightgrey'  # Change to your desired color\n",
    "\n",
    "pasted_submit_button.on_click(on_pasted_submit)\n",
    "save_button.on_click(on_save_click)\n",
    "\n",
    "# Arrange buttons side by side and center them using HBox\n",
    "button_layout = HBox([pasted_submit_button, save_button], layout=Layout(justify_content='center'))\n",
    "\n",
    "# Display the input fields and the button layout\n",
    "display(pasted_input_field, button_layout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
